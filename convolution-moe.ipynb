{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:24:57.912642Z","iopub.execute_input":"2025-09-13T05:24:57.912996Z","iopub.status.idle":"2025-09-13T05:24:57.917781Z","shell.execute_reply.started":"2025-09-13T05:24:57.912970Z","shell.execute_reply":"2025-09-13T05:24:57.916759Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"CIFAR 100 dataset has 20 superclasses each containing 5 subclasses.\n\nSo now I will be training 20 different models on each of the superclasses and then train the gating model for Mixture Of Experts.","metadata":{}},{"cell_type":"markdown","source":"So now for the 20 different models, I will be creating seperate training data and labels.","metadata":{}},{"cell_type":"code","source":"#This dictionary maps 100 fine grained classes to 20 coearse grained superclasses.\n\nfine_to_coarse_labels = {}\n\nfor i in range(0,100):\n    n = i // 5\n    fine_to_coarse_labels[i] = n\n\n    \nsuperclass_names = [\n    \"aquatic mammals\", \"fish\", \"flowers\", \"food containers\", \"fruit and vegetables\",\n    \"household electrical devices\", \"household furniture\", \"insects\", \"large carnivores\",\n    \"large man-made outdoor things\", \"large natural outdoor scenes\",\n    \"large omnivores and herbivores\", \"medium-sized mammals\", \"non-insect invertebrates\",\n    \"people\", \"reptiles\", \"small mammals\", \"trees\", \"vehicles 1\", \"vehicles 2\"\n]\n\ndef get_superclass_data():\n    (x_train_fine, y_train_fine), (x_test_fine, y_test_fine) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n    superclass_data = {}\n    test_data = {}\n\n    for name in superclass_names:\n        superclass_data[name] = {'images':[], 'labels':[]}\n        test_data[name] = {'images':[], 'labels':[]}\n\n    for i in range(len(x_train_fine)):\n        fine_label = y_train_fine[i][0]\n        coarse_label = fine_to_coarse_labels[fine_label]\n        superclass_name = superclass_names[coarse_label]\n\n        superclass_data[superclass_name]['images'].append(x_train_fine[i])\n        superclass_data[superclass_name]['labels'].append(fine_label)\n\n    for i in range(len(x_test_fine)):\n        fine_label = y_test_fine[i][0]\n        coarse_label = fine_to_coarse_labels[fine_label]\n        testclass_name = superclass_names[coarse_label]\n\n        test_data[testclass_name]['images'].append(x_test_fine[i])\n        test_data[testclass_name]['labels'].append(fine_label)\n\n    for name in superclass_names:\n        images = np.array(superclass_data[name]['images'])\n        labels = np.array(superclass_data[name]['labels'])\n        superclass_data[name] = (images,labels)\n\n    for name in superclass_names:\n        images = np.array(test_data[name]['images'])\n        labels = np.array(test_data[name]['labels'])\n        test_data[name] = (images,labels)\n    \n    return superclass_data, test_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:07:47.023616Z","iopub.execute_input":"2025-09-13T05:07:47.023933Z","iopub.status.idle":"2025-09-13T05:07:47.033570Z","shell.execute_reply.started":"2025-09-13T05:07:47.023901Z","shell.execute_reply":"2025-09-13T05:07:47.032592Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"superclass_data, testclass_data = get_superclass_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:07:51.843052Z","iopub.execute_input":"2025-09-13T05:07:51.843363Z","iopub.status.idle":"2025-09-13T05:07:57.570787Z","shell.execute_reply.started":"2025-09-13T05:07:51.843341Z","shell.execute_reply":"2025-09-13T05:07:57.570101Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"all_data = list(superclass_data.values())\nall_test_data = list(testclass_data.values())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:08:03.822518Z","iopub.execute_input":"2025-09-13T05:08:03.822827Z","iopub.status.idle":"2025-09-13T05:08:03.827344Z","shell.execute_reply.started":"2025-09-13T05:08:03.822802Z","shell.execute_reply":"2025-09-13T05:08:03.826352Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"all_images = []\nall_labels = []\n\nfor tup in all_data:\n    tup_l = list(tup)\n    all_images.append(tup_l[0])\n    all_labels.append(tup_l[1])\n\n\nall_test_images = []\nall_test_labels = []\n\nfor tup in all_test_data:\n    tup_l = list(tup)\n    all_test_images.append(tup_l[0])\n    all_test_labels.append(tup_l[1])\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:08:16.708081Z","iopub.execute_input":"2025-09-13T05:08:16.708374Z","iopub.status.idle":"2025-09-13T05:08:16.713992Z","shell.execute_reply.started":"2025-09-13T05:08:16.708352Z","shell.execute_reply":"2025-09-13T05:08:16.712990Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"Now building and training 20 different models each for a different superclass.","metadata":{}},{"cell_type":"code","source":"#Initially the model had no dropout layer in it due to which we were suffering from model overfitting and hence adding a dropout layer in the model\n\ndef build_model(num_classes):\n    model = Sequential([\n       # First Convolutional Block\n        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n        MaxPooling2D((2, 2)),\n        # Second Convolutional Block\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D((2, 2)),\n        # Third Convolutional Block\n        Conv2D(128, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D((2, 2)),\n        # Flatten the feature maps to feed into the dense layers\n        Flatten(),\n        #Dropout later to prevent overfitting\n        Dropout(0.6),\n        # Fully Connected Layers\n        Dense(128, activation='relu'),\n        # Output layer with 'num_classes' neurons for classification\n        Dense(num_classes, activation='softmax')\n    ])\n\n    model.compile(optimizer = 'adam',loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n\n    return model\n\ndef train_single_superclass_model(x_train_superclass,y_train_superclass,x_test_superclass,y_test_superclass,superclass_name,n_epochs):\n    y_train_flat = y_train_superclass.flatten()\n    y_test_flat = y_test_superclass.flatten()\n    unique_labels = np.unique(y_train_flat)\n    num_classes = len(unique_labels)\n    label_map = {label: i for i, label in enumerate(unique_labels)}\n    y_train_superclass_list = y_train_superclass.tolist()\n    y_test_superclass_list = y_test_superclass.tolist()\n    y_train_mapped = np.array([label_map[label] for label in y_train_flat])\n    y_test_mapped = np.array([label_map[label] for label in y_test_flat])\n\n    print(f\"\\n--- Building and training model for superclass: {superclass_name} ---\")\n    print(f\"Number of unique fine classes: {num_classes}\")\n\n    model = build_model(num_classes)\n    model.fit(x_train_superclass, y_train_mapped, epochs = n_epochs,batch_size = 32, verbose = 1)\n\n    print(f\"Training for {superclass_name} complete.\")\n\n    print(f\"\\n--- Evaluating model for superclass: {superclass_name} ---\")\n    loss, accuracy = model.evaluate(x_test_superclass, y_test_mapped, verbose=1)\n    \n    print(f\"Test Loss: {loss:.4f}\")\n    print(f\"Test Accuracy: {accuracy:.4f}\")\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:29:34.922816Z","iopub.execute_input":"2025-09-13T05:29:34.923114Z","iopub.status.idle":"2025-09-13T05:29:34.932570Z","shell.execute_reply.started":"2025-09-13T05:29:34.923093Z","shell.execute_reply":"2025-09-13T05:29:34.931795Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"aq_m_x_train = all_images[0]\nfish_x_train = all_images[1]\nflwr_x_train = all_images[2]\nfooc_x_train = all_images[3]\nfav_x_train = all_images[4]\nhed_x_train = all_images[5]\nhf_x_train = all_images[6]\nins_x_train = all_images[7]\nlc_x_train = all_images[8]\nlmot_x_train = all_images[9]\nlnos_x_train = all_images[10]\nloah_x_train = all_images[11]\nmsm_x_train = all_images[12]\nnii_x_train = all_images[13]\npeo_x_train = all_images[14]\nrep_x_train = all_images[15]\nsm_x_train = all_images[16]\ntrees_x_train = all_images[17]\nv1_x_train = all_images[18]\nv2_x_train = all_images[19]\n\n\naq_m_y_train = all_labels[0].reshape(-1,1)\nfish_y_train = all_labels[1].reshape(-1,1)\nflwr_y_train = all_labels[2].reshape(-1,1)\nfooc_y_train = all_labels[3].reshape(-1,1)\nfav_y_train = all_labels[4].reshape(-1,1)\nhed_y_train = all_labels[5].reshape(-1,1)\nhf_y_train = all_labels[6].reshape(-1,1)\nins_y_train = all_labels[7].reshape(-1,1)\nlc_y_train = all_labels[8].reshape(-1,1)\nlmot_y_train = all_labels[9].reshape(-1,1)\nlnos_y_train = all_labels[10].reshape(-1,1)\nloah_y_train = all_labels[11].reshape(-1,1)\nmsm_y_train = all_labels[12].reshape(-1,1)\nnii_y_train = all_labels[13].reshape(-1,1)\npeo_y_train = all_labels[14].reshape(-1,1)\nrep_y_train = all_labels[15].reshape(-1,1)\nsm_y_train = all_labels[16].reshape(-1,1)\ntrees_y_train = all_labels[17].reshape(-1,1)\nv1_y_train = all_labels[18].reshape(-1,1)\nv2_y_train = all_labels[19].reshape(-1,1)\n\n\n#For testing data\naq_m_x_test = all_test_images[0]\nfish_x_test = all_test_images[1]\nflwr_x_test = all_test_images[2]\nfooc_x_test = all_test_images[3]\nfav_x_test = all_test_images[4]\nhed_x_test = all_test_images[5]\nhf_x_test = all_test_images[6]\nins_x_test = all_test_images[7]\nlc_x_test = all_test_images[8]\nlmot_x_test = all_test_images[9]\nlnos_x_test = all_test_images[10]\nloah_x_test = all_test_images[11]\nmsm_x_test = all_test_images[12]\nnii_x_test = all_test_images[13]\npeo_x_test = all_test_images[14]\nrep_x_test = all_test_images[15]\nsm_x_test = all_test_images[16]\ntrees_x_test = all_test_images[17]\nv1_x_test = all_test_images[18]\nv2_x_test = all_test_images[19]\n\n\naq_m_y_test = all_test_labels[0].reshape(-1,1)\nfish_y_test = all_test_labels[1].reshape(-1,1)\nflwr_y_test = all_test_labels[2].reshape(-1,1)\nfooc_y_test = all_test_labels[3].reshape(-1,1)\nfav_y_test = all_test_labels[4].reshape(-1,1)\nhed_y_test = all_test_labels[5].reshape(-1,1)\nhf_y_test = all_test_labels[6].reshape(-1,1)\nins_y_test = all_test_labels[7].reshape(-1,1)\nlc_y_test = all_test_labels[8].reshape(-1,1)\nlmot_y_test = all_test_labels[9].reshape(-1,1)\nlnos_y_test = all_test_labels[10].reshape(-1,1)\nloah_y_test = all_test_labels[11].reshape(-1,1)\nmsm_y_test = all_test_labels[12].reshape(-1,1)\nnii_y_test = all_test_labels[13].reshape(-1,1)\npeo_y_test = all_test_labels[14].reshape(-1,1)\nrep_y_test = all_test_labels[15].reshape(-1,1)\nsm_y_test = all_test_labels[16].reshape(-1,1)\ntrees_y_test = all_test_labels[17].reshape(-1,1)\nv1_y_test = all_test_labels[18].reshape(-1,1)\nv2_y_test = all_test_labels[19].reshape(-1,1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:13:10.870260Z","iopub.execute_input":"2025-09-13T05:13:10.870615Z","iopub.status.idle":"2025-09-13T05:13:10.886059Z","shell.execute_reply.started":"2025-09-13T05:13:10.870590Z","shell.execute_reply":"2025-09-13T05:13:10.885223Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"Training the models per superclass","metadata":{}},{"cell_type":"code","source":"ne = 1\n\naq_model = train_single_superclass_model(aq_m_x_train,aq_m_y_train,aq_m_x_test,aq_m_y_test,superclass_names[0],ne)\nfish_model = train_single_superclass_model(fish_x_train,fish_y_train,fish_x_test,fish_y_test,superclass_names[1],ne)\nflwr_model = train_single_superclass_model(flwr_x_train,flwr_y_train,flwr_x_test,flwr_y_test,superclass_names[2],ne)\nfooc_model = train_single_superclass_model(fooc_x_train,fooc_y_train,fooc_x_test,fooc_y_test,superclass_names[3],ne)\nfav_model = train_single_superclass_model(fav_x_train,fav_y_train,fav_x_test,fav_y_test,superclass_names[4],ne)\nhed_model = train_single_superclass_model(hed_x_train,hed_y_train,hed_x_test,hed_y_test,superclass_names[5],ne)\nhf_model = train_single_superclass_model(hf_x_train,hf_y_train,hf_x_test,hf_y_test,superclass_names[6],ne)\nins_model = train_single_superclass_model(ins_x_train,ins_y_train,ins_x_test,ins_y_test,superclass_names[7],ne)\nlc_model = train_single_superclass_model(lc_x_train,lc_y_train,lc_x_test,lc_y_test,superclass_names[8],ne)\nlmot_model = train_single_superclass_model(lmot_x_train,lmot_y_train,lmot_x_test,lmot_y_test,superclass_names[9],ne)\nlnos_model = train_single_superclass_model(lnos_x_train,lnos_y_train,lnos_x_test,lnos_y_test,superclass_names[10],ne)\nloah_model = train_single_superclass_model(loah_x_train,loah_y_train,loah_x_test,loah_y_test,superclass_names[11],ne)\nmsm_model = train_single_superclass_model(msm_x_train,msm_y_train,msm_x_test,msm_y_test,superclass_names[12],ne)\nnii_model = train_single_superclass_model(nii_x_train,nii_y_train,nii_x_test,nii_y_test,superclass_names[13],ne)\npeo_model = train_single_superclass_model(peo_x_train,peo_y_train,peo_x_test,peo_y_test,superclass_names[14],ne)\nrep_model = train_single_superclass_model(rep_x_train,rep_y_train,rep_x_test,rep_y_test,superclass_names[15],ne)\nsm_model = train_single_superclass_model(sm_x_train,sm_y_train,sm_x_test,sm_y_test,superclass_names[16],ne)\ntrees_model = train_single_superclass_model(trees_x_train,trees_y_train,trees_x_test,trees_y_test,superclass_names[17],ne)\nv1_model = train_single_superclass_model(v1_x_train,v1_y_train,v1_x_test,v1_y_test,superclass_names[18],ne)\nv2_model = train_single_superclass_model(v2_x_train,v2_y_train,v2_x_test,v2_y_test,superclass_names[19],ne)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:43:45.728509Z","iopub.execute_input":"2025-09-13T05:43:45.729486Z","iopub.status.idle":"2025-09-13T05:45:37.600323Z","shell.execute_reply.started":"2025-09-13T05:43:45.729457Z","shell.execute_reply":"2025-09-13T05:45:37.599617Z"}},"outputs":[{"name":"stdout","text":"\n--- Building and training model for superclass: aquatic mammals ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.2848 - loss: 16.8964\nTraining for aquatic mammals complete.\n\n--- Evaluating model for superclass: aquatic mammals ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5506 - loss: 1.1334\nTest Loss: 1.1190\nTest Accuracy: 0.5740\n\n--- Building and training model for superclass: fish ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.2378 - loss: 16.3490\nTraining for fish complete.\n\n--- Evaluating model for superclass: fish ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3827 - loss: 1.4716\nTest Loss: 1.4791\nTest Accuracy: 0.3640\n\n--- Building and training model for superclass: flowers ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.2602 - loss: 14.1551\nTraining for flowers complete.\n\n--- Evaluating model for superclass: flowers ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.4020 - loss: 1.4075\nTest Loss: 1.3942\nTest Accuracy: 0.4120\n\n--- Building and training model for superclass: food containers ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.3003 - loss: 9.5943\nTraining for food containers complete.\n\n--- Evaluating model for superclass: food containers ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5243 - loss: 1.1433\nTest Loss: 1.1332\nTest Accuracy: 0.5320\n\n--- Building and training model for superclass: fruit and vegetables ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.2862 - loss: 17.1333\nTraining for fruit and vegetables complete.\n\n--- Evaluating model for superclass: fruit and vegetables ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6308 - loss: 1.0161\nTest Loss: 0.9967\nTest Accuracy: 0.6280\n\n--- Building and training model for superclass: household electrical devices ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.2164 - loss: 10.5809\nTraining for household electrical devices complete.\n\n--- Evaluating model for superclass: household electrical devices ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3804 - loss: 1.4735\nTest Loss: 1.4750\nTest Accuracy: 0.3700\n\n--- Building and training model for superclass: household furniture ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.3275 - loss: 12.0103\nTraining for household furniture complete.\n\n--- Evaluating model for superclass: household furniture ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6257 - loss: 1.0716\nTest Loss: 1.0571\nTest Accuracy: 0.6140\n\n--- Building and training model for superclass: insects ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.2703 - loss: 19.3094\nTraining for insects complete.\n\n--- Evaluating model for superclass: insects ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4469 - loss: 1.2865\nTest Loss: 1.3029\nTest Accuracy: 0.4540\n\n--- Building and training model for superclass: large carnivores ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.2699 - loss: 8.0656\nTraining for large carnivores complete.\n\n--- Evaluating model for superclass: large carnivores ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4820 - loss: 1.3619\nTest Loss: 1.3495\nTest Accuracy: 0.4880\n\n--- Building and training model for superclass: large man-made outdoor things ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.3445 - loss: 14.6597\nTraining for large man-made outdoor things complete.\n\n--- Evaluating model for superclass: large man-made outdoor things ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5774 - loss: 1.0645\nTest Loss: 1.0443\nTest Accuracy: 0.5800\n\n--- Building and training model for superclass: large natural outdoor scenes ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.3931 - loss: 14.3717\nTraining for large natural outdoor scenes complete.\n\n--- Evaluating model for superclass: large natural outdoor scenes ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7152 - loss: 0.7834\nTest Loss: 0.8206\nTest Accuracy: 0.6860\n\n--- Building and training model for superclass: large omnivores and herbivores ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.2910 - loss: 13.8867\nTraining for large omnivores and herbivores complete.\n\n--- Evaluating model for superclass: large omnivores and herbivores ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4993 - loss: 1.2488\nTest Loss: 1.2416\nTest Accuracy: 0.5060\n\n--- Building and training model for superclass: medium-sized mammals ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.3572 - loss: 10.5622\nTraining for medium-sized mammals complete.\n\n--- Evaluating model for superclass: medium-sized mammals ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6842 - loss: 0.8098\nTest Loss: 0.8011\nTest Accuracy: 0.6940\n\n--- Building and training model for superclass: non-insect invertebrates ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.3190 - loss: 14.3684\nTraining for non-insect invertebrates complete.\n\n--- Evaluating model for superclass: non-insect invertebrates ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5763 - loss: 1.0363\nTest Loss: 1.0348\nTest Accuracy: 0.5860\n\n--- Building and training model for superclass: people ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.3313 - loss: 15.0103\nTraining for people complete.\n\n--- Evaluating model for superclass: people ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6177 - loss: 1.0338\nTest Loss: 1.0089\nTest Accuracy: 0.6340\n\n--- Building and training model for superclass: reptiles ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.2965 - loss: 10.9463\nTraining for reptiles complete.\n\n--- Evaluating model for superclass: reptiles ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5429 - loss: 1.0935\nTest Loss: 1.1253\nTest Accuracy: 0.5340\n\n--- Building and training model for superclass: small mammals ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.3093 - loss: 15.3104\nTraining for small mammals complete.\n\n--- Evaluating model for superclass: small mammals ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5035 - loss: 1.1684\nTest Loss: 1.1413\nTest Accuracy: 0.5160\n\n--- Building and training model for superclass: trees ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.2824 - loss: 14.1784\nTraining for trees complete.\n\n--- Evaluating model for superclass: trees ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5235 - loss: 1.2897\nTest Loss: 1.2985\nTest Accuracy: 0.5120\n\n--- Building and training model for superclass: vehicles 1 ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.3262 - loss: 13.7618\nTraining for vehicles 1 complete.\n\n--- Evaluating model for superclass: vehicles 1 ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6153 - loss: 0.9792\nTest Loss: 1.0044\nTest Accuracy: 0.6020\n\n--- Building and training model for superclass: vehicles 2 ---\nNumber of unique fine classes: 5\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.3544 - loss: 14.1724\nTraining for vehicles 2 complete.\n\n--- Evaluating model for superclass: vehicles 2 ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5941 - loss: 1.0558\nTest Loss: 1.0737\nTest Accuracy: 0.5860\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T05:32:42.102832Z","iopub.execute_input":"2025-09-13T05:32:42.103169Z","iopub.status.idle":"2025-09-13T05:33:59.962465Z","shell.execute_reply.started":"2025-09-13T05:32:42.103147Z","shell.execute_reply":"2025-09-13T05:33:59.961692Z"}},"outputs":[{"name":"stdout","text":"\n--- Building and training model for superclass: fish ---\nNumber of unique fine classes: 5\nEpoch 1/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.2767 - loss: 14.2043\nEpoch 2/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.4363 - loss: 1.3776\nEpoch 3/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.4936 - loss: 1.2756\nEpoch 4/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.5584 - loss: 1.1593\nEpoch 5/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6209 - loss: 1.0012\nEpoch 6/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6482 - loss: 0.9260\nEpoch 7/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6604 - loss: 0.8881\nEpoch 8/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.7163 - loss: 0.7465\nEpoch 9/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.7209 - loss: 0.7526\nEpoch 10/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7344 - loss: 0.7202\nEpoch 11/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7445 - loss: 0.6819\nEpoch 12/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.7921 - loss: 0.5780\nEpoch 13/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7704 - loss: 0.6238\nEpoch 14/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.6384\nEpoch 15/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8045 - loss: 0.5355\nEpoch 16/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8096 - loss: 0.5195\nEpoch 17/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8409 - loss: 0.4417\nEpoch 18/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8446 - loss: 0.4385\nEpoch 19/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8659 - loss: 0.3572\nEpoch 20/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8614 - loss: 0.3828\nEpoch 21/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8607 - loss: 0.3890\nEpoch 22/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8601 - loss: 0.3656\nEpoch 23/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8650 - loss: 0.3517\nEpoch 24/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8631 - loss: 0.3522\nEpoch 25/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8958 - loss: 0.2773\nEpoch 26/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8954 - loss: 0.3189\nEpoch 27/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.8809 - loss: 0.3406\nEpoch 28/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8891 - loss: 0.3044\nEpoch 29/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9029 - loss: 0.2596\nEpoch 30/30\n\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8867 - loss: 0.3288\nTraining for fish complete.\n\n--- Evaluating model for superclass: fish ---\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8339 - loss: 0.5974\nTest Loss: 0.5593\nTest Accuracy: 0.8300\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}